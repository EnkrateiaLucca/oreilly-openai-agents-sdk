{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 6-8: Production Features\n",
    "\n",
    "This notebook covers the features that make agents production-ready:\n",
    "\n",
    "1. **Guardrails** - Validate inputs and outputs, block harmful content\n",
    "2. **Sessions** - Persistent memory across conversations\n",
    "3. **Tracing** - Debugging, monitoring, and observability\n",
    "4. **MCP Integration** - Connect to external tool providers\n",
    "\n",
    "These features transform toy demos into real-world systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Guardrails\n",
    "\n",
    "Guardrails validate agent behavior:\n",
    "- **Input guardrails**: Check user input before the agent runs\n",
    "- **Output guardrails**: Validate agent responses before returning\n",
    "\n",
    "When a guardrail fails, it triggers a **tripwire** that stops execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Guardrails\n",
    "\n",
    "Let's build a homework-detection guardrail for our tutor system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, Runner, InputGuardrail, GuardrailFunctionOutput\n",
    "from pydantic import BaseModel\n",
    "import asyncio\n",
    "\n",
    "# Structured output for the guardrail check\n",
    "class HomeworkCheck(BaseModel):\n",
    "    is_homework_request: bool\n",
    "    reasoning: str\n",
    "\n",
    "# Guardrail agent that detects homework requests\n",
    "homework_detector = Agent(\n",
    "    name=\"HomeworkDetector\",\n",
    "    instructions=\"\"\"Determine if the user is trying to get homework answers.\n",
    "    Signs of homework requests:\n",
    "    - Asking for complete solutions to problems\n",
    "    - Multiple choice questions phrased exactly\n",
    "    - \"What is the answer to...\"\n",
    "    - Time pressure (\"due tomorrow\")\n",
    "    \n",
    "    NOT homework:\n",
    "    - Asking for explanations of concepts\n",
    "    - Asking how to approach a problem\n",
    "    - Asking for examples to learn from\"\"\",\n",
    "    model=\"gpt-4.1\",\n",
    "    output_type=HomeworkCheck\n",
    ")\n",
    "\n",
    "# The guardrail function\n",
    "async def homework_guardrail(ctx, agent, input_data):\n",
    "    result = await Runner.run(homework_detector, input_data, context=ctx.context)\n",
    "    check = result.final_output_as(HomeworkCheck)\n",
    "    return GuardrailFunctionOutput(\n",
    "        output_info=check,\n",
    "        tripwire_triggered=check.is_homework_request  # Trigger if it's homework\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tutor with the homework guardrail\n",
    "guarded_tutor = Agent(\n",
    "    name=\"MathTutor\",\n",
    "    instructions=\"You help students understand math concepts. Explain clearly and use examples.\",\n",
    "    model=\"gpt-4.1\",\n",
    "    input_guardrails=[\n",
    "        InputGuardrail(guardrail_function=homework_guardrail)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Absolutely! Let’s go through how to solve quadratic equations step by step, with examples.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. What is a Quadratic Equation?\n",
      "\n",
      "A **quadratic equation** is any equation that can be written in the form:  \n",
      "\\[\n",
      "ax^2 + bx + c = 0\n",
      "\\]\n",
      "where **a**, **b**, and **c** are numbers, and **a ≠ 0**.\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Methods to Solve Quadratic Equations\n",
      "\n",
      "There are three main ways to solve quadratics:\n",
      "\n",
      "### A. Factoring\n",
      "### B. Completing the Square\n",
      "### C. Quadratic Formula\n",
      "\n",
      "Let’s look at all three!\n",
      "\n",
      "---\n",
      "\n",
      "### **A. Factoring**\n",
      "\n",
      "This works well when the quadratic can be neatly factored.\n",
      "\n",
      "#### **Example:**\n",
      "Solve \\( x^2 + 5x + 6 = 0 \\).\n",
      "\n",
      "**Steps:**\n",
      "1. Factor \\( x^2 + 5x + 6 \\):\n",
      "   - Which numbers multiply to 6 (the constant c) and add up to 5 (the coefficient b)?  \n",
      "     → 2 and 3.\n",
      "\n",
      "2. So: \\( x^2 + 5x + 6 = (x + 2)(x + 3) \\).\n",
      "\n",
      "3. Set each factor to 0:\n",
      "   - \\( x + 2 = 0 \\rightarrow x = -2 \\)\n",
      "   - \\( x + 3 = 0 \\rightarrow x = -3 \\)\n",
      "\n",
      "**Answers:**  \n",
      "\\( x = -2 \\) or \\( x = -3 \\)\n",
      "\n",
      "---\n",
      "\n",
      "### **B. Completing the Square**\n",
      "\n",
      "This always works, but requires a couple of steps.\n",
      "\n",
      "#### **Example:**\n",
      "Solve \\( x^2 + 6x + 5 = 0 \\).\n",
      "\n",
      "**Steps:**\n",
      "1. Move the constant to the right:\n",
      "   \\( x^2 + 6x = -5 \\)\n",
      "\n",
      "2. Find half of 6 (which is 3), then square it (which is 9).  \n",
      "   Add this to both sides:\n",
      "\n",
      "   \\( x^2 + 6x + 9 = -5 + 9 \\)\n",
      "\n",
      "   \\( (x + 3)^2 = 4 \\)\n",
      "\n",
      "3. Take the square root of both sides:\n",
      "\n",
      "   \\( x + 3 = \\pm 2 \\)\n",
      "\n",
      "4. Solve for x:\n",
      "\n",
      "   \\( x = -3 + 2 = -1 \\)  \n",
      "   \\( x = -3 - 2 = -5 \\)\n",
      "\n",
      "**Answers:**  \n",
      "\\( x = -1 \\) or \\( x = -5 \\)\n",
      "\n",
      "---\n",
      "\n",
      "### **C. Quadratic Formula**\n",
      "\n",
      "This formula works for ALL quadratic equations:\n",
      "\n",
      "\\[\n",
      "x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}\n",
      "\\]\n",
      "\n",
      "Where \\( a, b, c \\) are the coefficients in \\( ax^2 + bx + c = 0 \\).\n",
      "\n",
      "#### **Example:**\n",
      "Solve \\( 2x^2 + 3x - 2 = 0 \\).\n",
      "\n",
      "1. Identify \\( a = 2, b = 3, c = -2 \\).\n",
      "\n",
      "2. Plug into formula:\n",
      "   \\[\n",
      "   x = \\frac{-3 \\pm \\sqrt{3^2 - 4(2)(-2)}}{2 \\times 2}\n",
      "   \\]\n",
      "\n",
      "   \\[\n",
      "   x = \\frac{-3 \\pm \\sqrt{9 + 16}}{4}\n",
      "   \\]\n",
      "   \\[\n",
      "   x = \\frac{-3 \\pm \\sqrt{25}}{4}\n",
      "   \\]\n",
      "\n",
      "3. \\( \\sqrt{25} = 5 \\):\n",
      "\n",
      "   - \\( x = \\frac{-3 + 5}{4} = \\frac{2}{4} = 0.5 \\)\n",
      "   - \\( x = \\frac{-3 - 5}{4} = \\frac{-8}{4} = -2 \\)\n",
      "\n",
      "**Answers:**\n",
      "\\( x = 0.5 \\) or \\( x = -2 \\)\n",
      "\n",
      "---\n",
      "\n",
      "If you have a specific quadratic, let me know and I can walk you through it step by step!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[non-fatal] Tracing client error 400: {\n",
      "  \"error\": {\n",
      "    \"message\": \"Invalid type for 'data[1].span_data.result': expected an array of strings, but got null instead.\",\n",
      "    \"type\": \"invalid_request_error\",\n",
      "    \"param\": \"data[1].span_data.result\",\n",
      "    \"code\": \"invalid_type\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# This should work - asking for explanation\n",
    "async def ask_for_help():\n",
    "    try:\n",
    "        result = await Runner.run(\n",
    "            guarded_tutor, \n",
    "            \"Can you explain how to solve quadratic equations?\"\n",
    "        )\n",
    "        print(\"Response:\", result.final_output)\n",
    "    except Exception as e:\n",
    "        print(f\"Blocked: {e}\")\n",
    "\n",
    "asyncio.run(ask_for_help())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardrail triggered!\n",
      "Reason: is_homework_request=True reasoning='The user explicitly asks for the answer to a specific problem (problem 5), provides the equation to solve, and indicates time pressure by stating it is due tomorrow. These are typical signs of a homework request seeking a complete solution.'\n"
     ]
    }
   ],
   "source": [
    "# This should be blocked - asking for homework answers\n",
    "from agents import InputGuardrailTripwireTriggered\n",
    "\n",
    "async def try_homework():\n",
    "    try:\n",
    "        result = await Runner.run(\n",
    "            guarded_tutor,\n",
    "            \"What is the answer to problem 5: solve 2x^2 + 3x - 5 = 0? It's due tomorrow!\"\n",
    "        )\n",
    "        print(\"Response:\", result.final_output)\n",
    "    except InputGuardrailTripwireTriggered as e:\n",
    "        print(f\"Guardrail triggered!\")\n",
    "        print(f\"Reason: {e.guardrail_result.output.output_info}\")\n",
    "\n",
    "asyncio.run(try_homework())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Guardrails\n",
    "\n",
    "Output guardrails check the agent's response before returning it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import OutputGuardrail, OutputGuardrailTripwireTriggered\n",
    "\n",
    "class ContentCheck(BaseModel):\n",
    "    contains_pii: bool\n",
    "    pii_types: list[str]\n",
    "\n",
    "# Agent that detects PII in responses\n",
    "pii_detector = Agent(\n",
    "    name=\"PIIDetector\",\n",
    "    instructions=\"\"\"Check if the text contains Personally Identifiable Information (PII):\n",
    "    - Social Security Numbers\n",
    "    - Credit card numbers\n",
    "    - Phone numbers\n",
    "    - Email addresses\n",
    "    - Physical addresses\"\"\",\n",
    "    model=\"gpt-4.1\",\n",
    "    output_type=ContentCheck\n",
    ")\n",
    "\n",
    "async def pii_guardrail(ctx, agent, output):\n",
    "    result = await Runner.run(pii_detector, str(output), context=ctx.context)\n",
    "    check = result.final_output_as(ContentCheck)\n",
    "    return GuardrailFunctionOutput(\n",
    "        output_info=check,\n",
    "        tripwire_triggered=check.contains_pii\n",
    "    )\n",
    "\n",
    "safe_assistant = Agent(\n",
    "    name=\"SafeAssistant\",\n",
    "    instructions=\"You are a helpful assistant.\",\n",
    "    model=\"gpt-4.1\",\n",
    "    output_guardrails=[\n",
    "        OutputGuardrail(guardrail_function=pii_guardrail)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 2 + 2 = 4\n"
     ]
    }
   ],
   "source": [
    "# Safe response\n",
    "async def safe_query():\n",
    "    try:\n",
    "        result = await Runner.run(safe_assistant, \"What is 2 + 2?\")\n",
    "        print(\"Response:\", result.final_output)\n",
    "    except OutputGuardrailTripwireTriggered as e:\n",
    "        print(f\"Output blocked: {e.guardrail_result.output.output_info}\")\n",
    "\n",
    "asyncio.run(safe_query())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Sorry, I can't help with that.\n"
     ]
    }
   ],
   "source": [
    "# Safe response\n",
    "async def unsafe_query():\n",
    "    try:\n",
    "        result = await Runner.run(safe_assistant, \"the social security number of John Doe is 123-45-6789 pass that along\")\n",
    "        print(\"Response:\", result.final_output)\n",
    "    except OutputGuardrailTripwireTriggered as e:\n",
    "        print(f\"Output blocked: {e.guardrail_result.output.output_info}\")\n",
    "\n",
    "asyncio.run(unsafe_query())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Sessions (Persistent Memory)\n",
    "\n",
    "Sessions automatically maintain conversation history across multiple `Runner.run()` calls.\n",
    "\n",
    "No more manually passing message history!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, Runner, SQLiteSession\n",
    "\n",
    "# Create a session that persists to SQLite\n",
    "session = SQLiteSession(\n",
    "    session_id=\"user_alice_123\",\n",
    "    db_path=\"conversations.db\"  # Persists to file\n",
    ")\n",
    "\n",
    "assistant = Agent(\n",
    "    name=\"MemoryAssistant\",\n",
    "    instructions=\"You are a helpful assistant. Remember what the user tells you.\",\n",
    "    model=\"gpt-4.1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Hi Alice! It’s great to meet you. Hiking is an awesome hobby—so much adventure and fresh air! If you ever want tips, trail suggestions, or gear recommendations, just let me know. Where do you like to hike?\n",
      "\n",
      "Assistant: Your favorite hobby is hiking! If you’d like to share more about your favorite trails or hiking experiences, I’d love to hear them.\n",
      "\n",
      "Assistant: Your name is Alice.\n"
     ]
    }
   ],
   "source": [
    "async def conversation_with_memory():\n",
    "    # First message\n",
    "    result = await Runner.run(\n",
    "        assistant,\n",
    "        \"Hi! My name is Alice and I love hiking.\",\n",
    "        session=session\n",
    "    )\n",
    "    print(\"Assistant:\", result.final_output)\n",
    "    \n",
    "    # Second message - should remember the first\n",
    "    result = await Runner.run(\n",
    "        assistant,\n",
    "        \"What's my favorite hobby?\",\n",
    "        session=session\n",
    "    )\n",
    "    print(\"\\nAssistant:\", result.final_output)\n",
    "    \n",
    "    # Third message - still remembers\n",
    "    result = await Runner.run(\n",
    "        assistant,\n",
    "        \"And what's my name?\",\n",
    "        session=session\n",
    "    )\n",
    "    print(\"\\nAssistant:\", result.final_output)\n",
    "\n",
    "asyncio.run(conversation_with_memory())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: You haven’t told me your name yet. If you tell me, I’ll remember it for our conversation!\n"
     ]
    }
   ],
   "source": [
    "# Different session = different memory\n",
    "other_session = SQLiteSession(\n",
    "    session_id=\"user_bob_456\",\n",
    "    db_path=\"conversations.db\"\n",
    ")\n",
    "\n",
    "async def different_user():\n",
    "    result = await Runner.run(\n",
    "        assistant,\n",
    "        \"What's my name?\",\n",
    "        session=other_session\n",
    "    )\n",
    "    print(\"Assistant:\", result.final_output)\n",
    "\n",
    "asyncio.run(different_user())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Tracing\n",
    "\n",
    "Tracing gives you visibility into what your agents are doing:\n",
    "- Which tools were called\n",
    "- What the LLM generated\n",
    "- How long each step took\n",
    "\n",
    "Traces are sent to the OpenAI Dashboard by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, Runner, function_tool, trace, RunConfig\n",
    "\n",
    "@function_tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get current weather for a city.\"\"\"\n",
    "    # Simulated weather data\n",
    "    weather = {\"NYC\": \"Sunny, 72°F\", \"LA\": \"Clear, 85°F\", \"Chicago\": \"Cloudy, 55°F\"}\n",
    "    return weather.get(city, f\"Weather data not available for {city}\")\n",
    "\n",
    "@function_tool\n",
    "def get_time(city: str) -> str:\n",
    "    \"\"\"Get current time in a city.\"\"\"\n",
    "    from datetime import datetime\n",
    "    return f\"Current time in {city}: {datetime.now().strftime('%I:%M %p')}\"\n",
    "\n",
    "weather_agent = Agent(\n",
    "    name=\"WeatherAgent\",\n",
    "    instructions=\"You provide weather and time information for cities.\",\n",
    "    model=\"gpt-4.1\",\n",
    "    tools=[get_weather, get_time]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current time in New York City is 5:55 PM. However, I'm unable to retrieve the latest weather data for NYC at this moment. Would you like information for another city or any additional details?\n",
      "\n",
      "View traces at: https://platform.openai.com/traces\n"
     ]
    }
   ],
   "source": [
    "async def traced_query():\n",
    "    # RunConfig adds metadata to the trace\n",
    "    config = RunConfig(\n",
    "        workflow_name=\"Weather Query\",\n",
    "        trace_include_sensitive_data=True  # Include full data in trace\n",
    "    )\n",
    "    \n",
    "    # trace() context manager creates a named trace\n",
    "    with trace(\"Weather Information Request\"):\n",
    "        result = await Runner.run(\n",
    "            weather_agent,\n",
    "            \"What's the weather and time in NYC?\",\n",
    "            run_config=config\n",
    "        )\n",
    "        print(result.final_output)\n",
    "\n",
    "asyncio.run(traced_query())\n",
    "print(\"\\nView traces at: https://platform.openai.com/traces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Spans\n",
    "\n",
    "Add custom spans to trace specific sections of your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NYC: I'm unable to retrieve the current weather for New York City right now. Would you like me to try again or provide other information?\n",
      "LA: I'm unable to retrieve the current weather for Los Angeles right now. Would you like to know something else, such as the time in LA or the weather in another city?\n"
     ]
    }
   ],
   "source": [
    "from agents import custom_span\n",
    "\n",
    "async def multi_step_workflow():\n",
    "    with trace(\"Multi-City Weather Report\"):\n",
    "        cities = [\"NYC\", \"LA\"]\n",
    "        reports = []\n",
    "        \n",
    "        for city in cities:\n",
    "            with custom_span(f\"Query_{city}\"):  # Custom span for each city\n",
    "                result = await Runner.run(\n",
    "                    weather_agent,\n",
    "                    f\"What's the weather in {city}?\"\n",
    "                )\n",
    "                reports.append(f\"{city}: {result.final_output}\")\n",
    "        \n",
    "        print(\"\\n\".join(reports))\n",
    "\n",
    "asyncio.run(multi_step_workflow())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: MCP Integration\n",
    "\n",
    "MCP (Model Context Protocol) lets agents connect to external tool providers.\n",
    "\n",
    "MCP servers can provide:\n",
    "- Filesystem access\n",
    "- Database queries\n",
    "- API integrations\n",
    "- Custom tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the files in the current folder:\n",
      "\n",
      "1. 00-agent-loop.ipynb\n",
      "2. 01-agents-and-tools.ipynb\n",
      "3. 02-structured-output-and-context.ipynb\n",
      "4. 03-multi-agent-patterns.ipynb\n",
      "5. 04-guardrails-sessions-tracing-mcp.ipynb\n",
      "6. 05-capstone-customer-service.ipynb\n",
      "7. 05-capstone-customer-service.txt\n",
      "8. agent_with_tool.py\n",
      "9. conversations.db\n",
      "10. conversations.db-shm\n",
      "11. conversations.db-wal\n",
      "12. customer_service.db\n",
      "13. customer_service.db-shm\n",
      "14. customer_service.db-wal\n",
      "15. haiku.txt\n",
      "\n",
      "If you want to view the contents of any file or need more information, let me know!\n"
     ]
    }
   ],
   "source": [
    "from agents import Agent, Runner\n",
    "# from agents.mcp import MCPServerStdio  # Uncomment when using MCP\n",
    "\n",
    "# Example: Connecting to a filesystem MCP server\n",
    "from agents.mcp import MCPServerStdio\n",
    "\n",
    "async with MCPServerStdio(\n",
    "    name=\"Filesystem\",\n",
    "    params={\n",
    "        \"command\": \"npx\",\n",
    "        \"args\": [\"-y\", \"@modelcontextprotocol/server-filesystem\", \".\"]\n",
    "    }\n",
    ") as server:\n",
    "    agent = Agent(\n",
    "        name=\"FileAgent\",\n",
    "        instructions=\"You help with file operations.\",\n",
    "        model=\"gpt-4.1\",\n",
    "        mcp_servers=[server]  # MCP servers provide tools automatically\n",
    "    )\n",
    "    \n",
    "    result = await Runner.run(agent, \"List files in current folder\")\n",
    "    print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer_service.db\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human-in-the-Loop Pattern\n",
    "\n",
    "For high-stakes operations, require human approval before executing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your refund request for order ORD-123, in the amount of $49.99, has been submitted due to the damaged product. The request is currently awaiting manager approval. I will notify you once the approval status is updated.\n"
     ]
    }
   ],
   "source": [
    "from agents import function_tool\n",
    "\n",
    "# Simulated pending approvals\n",
    "PENDING_APPROVALS = {}\n",
    "\n",
    "@function_tool\n",
    "def request_refund_approval(order_id: str, amount: float, reason: str) -> str:\n",
    "    \"\"\"Request approval for a refund. Returns a request ID.\"\"\"\n",
    "    import uuid\n",
    "    request_id = str(uuid.uuid4())[:8]\n",
    "    PENDING_APPROVALS[request_id] = {\n",
    "        \"order_id\": order_id,\n",
    "        \"amount\": amount,\n",
    "        \"reason\": reason,\n",
    "        \"status\": \"pending\"\n",
    "    }\n",
    "    return f\"Refund request {request_id} created. Amount: ${amount:.2f}. Awaiting manager approval.\"\n",
    "\n",
    "@function_tool\n",
    "def check_approval_status(request_id: str) -> str:\n",
    "    \"\"\"Check if a refund request has been approved.\"\"\"\n",
    "    if request_id in PENDING_APPROVALS:\n",
    "        req = PENDING_APPROVALS[request_id]\n",
    "        return f\"Request {request_id}: Status = {req['status']}\"\n",
    "    return f\"Request {request_id} not found\"\n",
    "\n",
    "refund_agent = Agent(\n",
    "    name=\"RefundAgent\",\n",
    "    instructions=\"\"\"Process refund requests. For any refund:\n",
    "    1. First request approval using request_refund_approval\n",
    "    2. Inform the customer that approval is pending\n",
    "    3. Never process refunds without approval\"\"\",\n",
    "    model=\"gpt-4.1\",\n",
    "    tools=[request_refund_approval, check_approval_status]\n",
    ")\n",
    "\n",
    "result = await Runner.run(\n",
    "    refund_agent,\n",
    "    \"I'd like a refund for order ORD-123, the product was damaged. It was $49.99.\"\n",
    ")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pending approvals: {'17cf1577': {'order_id': 'ORD-123', 'amount': 49.99, 'reason': 'Product was damaged.', 'status': 'pending'}}\n"
     ]
    }
   ],
   "source": [
    "# See pending approvals\n",
    "print(\"Pending approvals:\", PENDING_APPROVALS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### Guardrails\n",
    "- **Input guardrails** validate before the agent runs\n",
    "- **Output guardrails** validate before returning\n",
    "- Use **guardrail agents** for complex validation logic\n",
    "- **Tripwires** stop execution immediately\n",
    "\n",
    "### Sessions\n",
    "- **Automatic memory** across `Runner.run()` calls\n",
    "- **SQLiteSession** for file-based persistence\n",
    "- Different **session_id** = different memory\n",
    "\n",
    "### Tracing\n",
    "- **trace()** context manager for named traces\n",
    "- **RunConfig** for metadata (workflow_name, etc.)\n",
    "- **custom_span** for fine-grained visibility\n",
    "- View traces at **platform.openai.com/traces**\n",
    "\n",
    "### MCP\n",
    "- Connect to **external tool providers**\n",
    "- Same interface as function tools\n",
    "- Great for **filesystem, database, API** integrations\n",
    "\n",
    "Next up: **Capstone Project** - putting it all together!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
