{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 4-5: Multi-Agent Patterns\n",
    "\n",
    "This notebook covers two ways to orchestrate multiple agents:\n",
    "\n",
    "1. **Handoffs** - Decentralized delegation (agent transfers control to another)\n",
    "2. **Agents-as-Tools** - Centralized orchestration (manager calls agents as tools)\n",
    "\n",
    "## The Key Question\n",
    "\n",
    "When should you use **handoffs** vs **agents-as-tools**?\n",
    "\n",
    "| Pattern | Control Flow | Best For |\n",
    "|---------|--------------|----------|\n",
    "| Handoffs | Transfer control completely | Specialist completes the entire task |\n",
    "| Agents-as-Tools | Manager stays in control | Combining results from multiple specialists |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Handoffs (Decentralized Delegation)\n",
    "\n",
    "A **handoff** transfers the entire conversation to another agent. The new agent:\n",
    "- Gets the full conversation history\n",
    "- Takes over completely\n",
    "- Produces the final response\n",
    "\n",
    "Think of it like transferring a phone call to a specialist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, Runner, enable_verbose_stdout_logging\n",
    "\n",
    "# Enable verbose logging to visualize execution\n",
    "enable_verbose_stdout_logging()\n",
    "\n",
    "# Create specialist agents\n",
    "math_tutor = Agent(\n",
    "    name=\"MathTutor\",\n",
    "    instructions=\"\"\"You are a math tutor. Help students understand math concepts.\n",
    "    - Explain step by step\n",
    "    - Use examples\n",
    "    - Be encouraging\"\"\",\n",
    "    model=\"gpt-4.1\",\n",
    "    handoff_description=\"Hand off for math questions (algebra, calculus, geometry, etc.)\"\n",
    ")\n",
    "\n",
    "history_tutor = Agent(\n",
    "    name=\"HistoryTutor\",\n",
    "    instructions=\"\"\"You are a history tutor. Help students understand historical events.\n",
    "    - Provide context and background\n",
    "    - Discuss causes and effects\n",
    "    - Make connections to modern times\"\"\",\n",
    "    model=\"gpt-4.1\",\n",
    "    handoff_description=\"Hand off for history questions (events, periods, historical figures)\"\n",
    ")\n",
    "\n",
    "# Create triage agent that routes to specialists\n",
    "triage_agent = Agent(\n",
    "    name=\"TutorTriage\",\n",
    "    instructions=\"\"\"You are the front desk of a tutoring center.\n",
    "    Determine what subject the student needs help with and hand off to the appropriate tutor.\n",
    "    If the question isn't about math or history, politely explain we only offer those subjects.\"\"\",\n",
    "    model=\"gpt-4.1\",\n",
    "    handoffs=[math_tutor, history_tutor]  # <-- Handoffs go here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating trace Agent workflow with id trace_5c845a68d35641eb8b3bb801f7e71c78\n",
      "Setting current trace: trace_5c845a68d35641eb8b3bb801f7e71c78\n",
      "Creating span <agents.tracing.span_data.AgentSpanData object at 0x119df01d0> with id None\n",
      "Running agent TutorTriage (turn 1)\n",
      "No conversation_id available for request\n",
      "Creating span <agents.tracing.span_data.ResponseSpanData object at 0x11b535270> with id None\n",
      "Calling LLM\n",
      "LLM responded\n",
      "Processing output item type=function_call class=ResponseFunctionToolCall\n",
      "Creating span <agents.tracing.span_data.HandoffSpanData object at 0x119c77ed0> with id None\n",
      "Creating span <agents.tracing.span_data.AgentSpanData object at 0x11d188e90> with id None\n",
      "Running agent MathTutor (turn 2)\n",
      "No conversation_id available for request\n",
      "Creating span <agents.tracing.span_data.ResponseSpanData object at 0x11d1094f0> with id None\n",
      "Calling LLM\n",
      "LLM responded\n",
      "Processing output item type=message class=ResponseOutputMessage\n",
      "Resetting current trace\n",
      "Absolutely! Let's solve the equation step by step:\n",
      "\n",
      "2x + 5 = 13\n",
      "\n",
      "Step 1: Get x by itself.  \n",
      "First, subtract 5 from both sides to move the constant term:\n",
      "2x + 5 − 5 = 13 − 5  \n",
      "2x = 8\n",
      "\n",
      "Step 2: Divide both sides by 2 to solve for x:\n",
      "2x ÷ 2 = 8 ÷ 2  \n",
      "x = 4\n",
      "\n",
      "Example Check:  \n",
      "Let’s check our answer by plugging x = 4 back into the original equation:\n",
      "\n",
      "2(4) + 5 = 8 + 5 = 13\n",
      "\n",
      "It works!\n",
      "\n",
      "You got it! The solution is:\n",
      "x = 4\n",
      "\n",
      "Nice work! Do you want to try another one?\n"
     ]
    }
   ],
   "source": [
    "# Test with a math question\n",
    "result = await Runner.run(triage_agent, \"Can you help me solve 2x + 5 = 13?\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating trace Agent workflow with id trace_2fd744f29cb047a89e0e01ba2cfd32b7\n",
      "Setting current trace: trace_2fd744f29cb047a89e0e01ba2cfd32b7\n",
      "Creating span <agents.tracing.span_data.AgentSpanData object at 0x119df01d0> with id None\n",
      "Running agent TutorTriage (turn 1)\n",
      "No conversation_id available for request\n",
      "Creating span <agents.tracing.span_data.ResponseSpanData object at 0x11d108780> with id None\n",
      "Calling LLM\n",
      "LLM responded\n",
      "Processing output item type=function_call class=ResponseFunctionToolCall\n",
      "Creating span <agents.tracing.span_data.HandoffSpanData object at 0x11b2bf480> with id None\n",
      "Creating span <agents.tracing.span_data.AgentSpanData object at 0x11d189430> with id None\n",
      "Running agent HistoryTutor (turn 2)\n",
      "No conversation_id available for request\n",
      "Creating span <agents.tracing.span_data.ResponseSpanData object at 0x11d1080a0> with id None\n",
      "Calling LLM\n",
      "LLM responded\n",
      "Processing output item type=message class=ResponseOutputMessage\n",
      "Resetting current trace\n",
      "**Context and Background:**\n",
      "World War I (1914-1918), also known as the Great War, was a global conflict centered in Europe but affecting countries worldwide. By the early 20th century, Europe was dominated by powerful empires, intense nationalism, and complex alliances.\n",
      "\n",
      "**Main Causes of World War I:**\n",
      "\n",
      "1. **Militarism:**  \n",
      "   European nations were building up massive military forces, believing that might equaled right. This arms race, especially between Germany and Britain, created a tense environment where even a small incident could escalate.\n",
      "\n",
      "2. **Alliances:**  \n",
      "   Europe was split into two major alliance systems:\n",
      "   - The Triple Entente (France, Russia, Britain)\n",
      "   - The Triple Alliance (Germany, Austria-Hungary, Italy)\n",
      "   These alliances meant that if one nation was attacked, allied nations were obligated to join the conflict—spreading any small war into a major one.\n",
      "\n",
      "3. **Imperialism:**  \n",
      "   European powers competed fiercely for colonies and resources, especially in Africa and Asia. This competition created resentment and rivalries, adding to tensions at home.\n",
      "\n",
      "4. **Nationalism:**  \n",
      "   Ethnic groups and nations wanted to assert their independence or dominance. For example, Slavic nationalism in the Balkans threatened Austria-Hungary, and French anger over Germany’s annexation of Alsace-Lorraine (after the Franco-Prussian War) was still strong.\n",
      "\n",
      "5. **Assassination:**  \n",
      "   The immediate spark was the assassination of Archduke Franz Ferdinand of Austria-Hungary by a Serbian nationalist in June 1914. Austria-Hungary issued an ultimatum to Serbia; when it wasn't fully accepted, Austria-Hungary declared war, triggering a chain reaction among the alliances.\n",
      "\n",
      "**Immediate Effects:**\n",
      "Within weeks, Europe was at war. By August 1914, major powers were involved due to the web of alliances, diplomacy failures, and aggressive military plans.\n",
      "\n",
      "**Connections to Modern Times:**\n",
      "- **Alliances:** NATO and other modern alliances are direct descendants of this era, though with improved diplomatic mechanisms.\n",
      "- **Nationalism:** Modern instances of nationalism and ethnic conflict still lead to tension and violence.\n",
      "- **Regional Conflicts:** Many contemporary conflicts begin in one place and draw in other nations, reminding us of how local events can have global consequences.\n",
      "\n",
      "**Why It Matters:**\n",
      "Understanding the causes of WWI shows how a mix of political, economic, and cultural factors, plus a single event, can trigger world-changing events. It also highlights why careful diplomacy, communication, and conflict prevention are still critical in global politics today.\n"
     ]
    }
   ],
   "source": [
    "# Test with a history question\n",
    "result = await Runner.run(triage_agent, \"What caused World War I?\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating trace Agent workflow with id trace_555c8e9e2ddb4292a2adebc2ccf5e26b\n",
      "Setting current trace: trace_555c8e9e2ddb4292a2adebc2ccf5e26b\n",
      "Creating span <agents.tracing.span_data.AgentSpanData object at 0x11d188b90> with id None\n",
      "Running agent TutorTriage (turn 1)\n",
      "No conversation_id available for request\n",
      "Creating span <agents.tracing.span_data.ResponseSpanData object at 0x11d16d900> with id None\n",
      "Calling LLM\n",
      "LLM responded\n",
      "Processing output item type=message class=ResponseOutputMessage\n",
      "Resetting current trace\n",
      "I'm sorry, but we currently only offer tutoring in math and history. If you need help with either of those subjects, I'd be happy to assist!\n"
     ]
    }
   ],
   "source": [
    "# Disable verbose logging before running the test with an unsupported subject\n",
    "\n",
    "result = await Runner.run(triage_agent, \"Can you help me with my chemistry homework?\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Agent Graph\n",
    "\n",
    "The SDK includes a visualization tool to see agent relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Requires graphviz to be installed\n",
    "# pip install openai-agents[viz]\n",
    "try:\n",
    "    from agents.extensions.visualization import draw_graph\n",
    "    draw_graph(triage_agent)\n",
    "except ImportError:\n",
    "    print(\"Install visualization support: pip install openai-agents[viz]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 13.0.1 (20250615.1724)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"242pt\" height=\"298pt\"\n",
       " viewBox=\"0.00 0.00 242.00 298.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 294.38)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-294.38 238,-294.38 238,4 -4,4\"/>\n",
       "<!-- __start__ -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>__start__</title>\n",
       "<ellipse fill=\"lightblue\" stroke=\"black\" cx=\"117\" cy=\"-273.58\" rx=\"51.09\" ry=\"16.79\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"117\" y=\"-268.16\" font-family=\"Arial\" font-size=\"14.00\">__start__</text>\n",
       "</g>\n",
       "<!-- TutorTriage -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>TutorTriage</title>\n",
       "<polygon fill=\"lightyellow\" stroke=\"black\" points=\"171,-220.79 63,-220.79 63,-163.19 171,-163.19 171,-220.79\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"117\" y=\"-186.56\" font-family=\"Arial\" font-size=\"14.00\">TutorTriage</text>\n",
       "</g>\n",
       "<!-- __start__&#45;&gt;TutorTriage -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>__start__&#45;&gt;TutorTriage</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"1.5\" d=\"M117,-256.47C117,-249.64 117,-241.34 117,-233.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" stroke-width=\"1.5\" points=\"120.5,-233.26 117,-223.26 113.5,-233.26 120.5,-233.26\"/>\n",
       "</g>\n",
       "<!-- __end__ -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>__end__</title>\n",
       "<ellipse fill=\"lightblue\" stroke=\"black\" cx=\"117\" cy=\"-16.79\" rx=\"48.44\" ry=\"16.79\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"117\" y=\"-11.37\" font-family=\"Arial\" font-size=\"14.00\">__end__</text>\n",
       "</g>\n",
       "<!-- MathTutor -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>MathTutor</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M96,-127.19C96,-127.19 12,-127.19 12,-127.19 6,-127.19 0,-121.19 0,-115.19 0,-115.19 0,-81.59 0,-81.59 0,-75.59 6,-69.59 12,-69.59 12,-69.59 96,-69.59 96,-69.59 102,-69.59 108,-75.59 108,-81.59 108,-81.59 108,-115.19 108,-115.19 108,-121.19 102,-127.19 96,-127.19\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"54\" y=\"-92.96\" font-family=\"Arial\" font-size=\"14.00\">MathTutor</text>\n",
       "</g>\n",
       "<!-- TutorTriage&#45;&gt;MathTutor -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>TutorTriage&#45;&gt;MathTutor</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"1.5\" d=\"M97.76,-163.01C92.19,-154.91 86.02,-145.94 80.11,-137.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" stroke-width=\"1.5\" points=\"83.18,-135.64 74.63,-129.38 77.41,-139.61 83.18,-135.64\"/>\n",
       "</g>\n",
       "<!-- HistoryTutor -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>HistoryTutor</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M222,-127.19C222,-127.19 138,-127.19 138,-127.19 132,-127.19 126,-121.19 126,-115.19 126,-115.19 126,-81.59 126,-81.59 126,-75.59 132,-69.59 138,-69.59 138,-69.59 222,-69.59 222,-69.59 228,-69.59 234,-75.59 234,-81.59 234,-81.59 234,-115.19 234,-115.19 234,-121.19 228,-127.19 222,-127.19\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"180\" y=\"-92.96\" font-family=\"Arial\" font-size=\"14.00\">HistoryTutor</text>\n",
       "</g>\n",
       "<!-- TutorTriage&#45;&gt;HistoryTutor -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>TutorTriage&#45;&gt;HistoryTutor</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"1.5\" d=\"M136.24,-163.01C141.81,-154.91 147.98,-145.94 153.89,-137.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" stroke-width=\"1.5\" points=\"156.59,-139.61 159.37,-129.38 150.82,-135.64 156.59,-139.61\"/>\n",
       "</g>\n",
       "<!-- MathTutor&#45;&gt;__end__ -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>MathTutor&#45;&gt;__end__</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"1.5\" d=\"M76.39,-69.1C83.13,-60.59 90.47,-51.31 97.04,-43.01\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" stroke-width=\"1.5\" points=\"99.71,-45.28 103.17,-35.27 94.22,-40.94 99.71,-45.28\"/>\n",
       "</g>\n",
       "<!-- HistoryTutor&#45;&gt;__end__ -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>HistoryTutor&#45;&gt;__end__</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"1.5\" d=\"M157.61,-69.1C150.87,-60.59 143.53,-51.31 136.96,-43.01\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" stroke-width=\"1.5\" points=\"139.78,-40.94 130.83,-35.27 134.29,-45.28 139.78,-40.94\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x11d183250>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_graph(triage_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Handoffs Work Under the Hood\n",
    "\n",
    "When you define `handoffs=[agent1, agent2]`, the SDK:\n",
    "\n",
    "1. Creates a tool for each agent: `transfer_to_math_tutor`, `transfer_to_history_tutor`\n",
    "2. Uses `handoff_description` as the tool description\n",
    "3. When the LLM calls the transfer tool, the new agent takes over\n",
    "4. The new agent receives the full conversation history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Agents-as-Tools (Centralized Orchestration)\n",
    "\n",
    "With `agent.as_tool()`, you call another agent like a function:\n",
    "- The manager agent stays in control\n",
    "- Gets results back from sub-agents\n",
    "- Can call multiple agents and synthesize results\n",
    "\n",
    "Think of it like a manager delegating tasks to team members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create specialist agents\n",
    "summarizer = Agent(\n",
    "    name=\"Summarizer\",\n",
    "    instructions=\"\"\"You summarize text concisely.\n",
    "    - Extract key points\n",
    "    - Keep it brief (2-3 sentences)\n",
    "    - Maintain accuracy\"\"\",\n",
    "    model=\"gpt-4.1\"\n",
    ")\n",
    "\n",
    "fact_checker = Agent(\n",
    "    name=\"FactChecker\",\n",
    "    instructions=\"\"\"You verify factual claims.\n",
    "    - Identify factual statements\n",
    "    - Note any potential issues or inaccuracies\n",
    "    - Be skeptical but fair\"\"\",\n",
    "    model=\"gpt-4.1\"\n",
    ")\n",
    "\n",
    "# Create a manager that uses agents as tools\n",
    "research_manager = Agent(\n",
    "    name=\"ResearchManager\",\n",
    "    instructions=\"\"\"You are a research manager. When given content to analyze:\n",
    "    1. Use the summarizer to get a concise summary\n",
    "    2. Use the fact_checker to verify claims\n",
    "    3. Combine both results into a final report\"\"\",\n",
    "    model=\"gpt-4.1\",\n",
    "    tools=[\n",
    "        summarizer.as_tool(\n",
    "            tool_name=\"summarize\",\n",
    "            tool_description=\"Summarize the given text concisely\"\n",
    "        ),\n",
    "        fact_checker.as_tool(\n",
    "            tool_name=\"check_facts\",\n",
    "            tool_description=\"Verify factual claims in the text\"\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating trace Agent workflow with id trace_c3d9a2b0967c49179bfc1ece3e7b389f\n",
      "Setting current trace: trace_c3d9a2b0967c49179bfc1ece3e7b389f\n",
      "Creating span <agents.tracing.span_data.AgentSpanData object at 0x10596bb90> with id None\n",
      "Running agent ResearchManager (turn 1)\n",
      "No conversation_id available for request\n",
      "Creating span <agents.tracing.span_data.ResponseSpanData object at 0x11b536850> with id None\n",
      "Calling LLM\n",
      "LLM responded\n",
      "Processing output item type=function_call class=ResponseFunctionToolCall\n",
      "Processing output item type=function_call class=ResponseFunctionToolCall\n",
      "Creating span <agents.tracing.span_data.FunctionSpanData object at 0x11d1ec530> with id None\n",
      "Creating span <agents.tracing.span_data.FunctionSpanData object at 0x11b00b050> with id None\n",
      "Invoking tool summarize\n",
      "Creating span <agents.tracing.span_data.AgentSpanData object at 0x11d1ecad0> with id None\n",
      "Running agent Summarizer (turn 1)\n",
      "Invoking tool check_facts\n",
      "Creating span <agents.tracing.span_data.AgentSpanData object at 0x11d1ec8f0> with id None\n",
      "Running agent FactChecker (turn 1)\n",
      "No conversation_id available for request\n",
      "Creating span <agents.tracing.span_data.ResponseSpanData object at 0x11d1fc050> with id None\n",
      "Calling LLM\n",
      "No conversation_id available for request\n",
      "Creating span <agents.tracing.span_data.ResponseSpanData object at 0x11d1fc5a0> with id None\n",
      "Calling LLM\n",
      "LLM responded\n",
      "Processing output item type=message class=ResponseOutputMessage\n",
      "LLM responded\n",
      "Processing output item type=message class=ResponseOutputMessage\n",
      "Running agent ResearchManager (turn 2)\n",
      "No conversation_id available for request\n",
      "Creating span <agents.tracing.span_data.ResponseSpanData object at 0x11d16d900> with id None\n",
      "Calling LLM\n",
      "LLM responded\n",
      "Processing output item type=message class=ResponseOutputMessage\n",
      "Resetting current trace\n",
      "Report:\n",
      "\n",
      "Summary:\n",
      "The Great Wall of China is the longest wall in the world, spanning over 13,000 miles, and was constructed primarily to defend against Mongolian invaders, featuring numerous watchtowers. However, contrary to some common beliefs, the wall was not built entirely during the Ming Dynasty, did not take only 50 years to complete, and is not visible from space with the naked eye.\n",
      "\n",
      "Fact Verification:\n",
      "- The wall's length (about 13,000 miles) and defensive role are mostly accurate, though the total length includes multiple segments built over several eras.\n",
      "- It was not built entirely during the Ming Dynasty; construction began centuries earlier, with major segments from different periods.\n",
      "- The claim of a 50-year construction window is false; Ming Dynasty construction alone spanned over 200 years.\n",
      "- The wall is not visible to the naked eye from space according to astronaut accounts—this is a persistent myth.\n",
      "- Watchtower spacing is not fixed at 100 meters; it widely varies based on terrain and historical needs.\n",
      "\n",
      "Final Assessment:\n",
      "While the content accurately reflects the wall's significance and scale, it contains several inaccuracies: the time frame and period of construction, visibility from space, and uniformity of watchtower spacing are all incorrect or overstated. The wall’s construction and features are more complex than the simplified statements suggest.\n"
     ]
    }
   ],
   "source": [
    "content = \"\"\"\n",
    "The Great Wall of China is the longest wall in the world, stretching over 13,000 miles.\n",
    "It was built entirely during the Ming Dynasty and took only 50 years to complete.\n",
    "The wall is visible from space with the naked eye. It was primarily built to keep out\n",
    "Mongolian invaders and features watchtowers every 100 meters.\n",
    "\"\"\"\n",
    "\n",
    "result = await Runner.run(research_manager, f\"Analyze this content:\\n{content}\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the manager:\n",
    "1. Called the summarizer\n",
    "2. Called the fact checker\n",
    "3. Combined the results into a coherent report\n",
    "\n",
    "The manager **stayed in control** throughout - unlike handoffs where control transfers completely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Framework: Handoffs vs Agents-as-Tools\n",
    "\n",
    "### Use Handoffs When:\n",
    "- The specialist should **complete the entire task**\n",
    "- User should **interact directly** with the specialist\n",
    "- No need to **return to the original agent**\n",
    "- Example: Customer support triage → specialist handles the whole issue\n",
    "\n",
    "### Use Agents-as-Tools When:\n",
    "- Manager needs to **coordinate multiple specialists**\n",
    "- Results need to be **combined or synthesized**\n",
    "- Manager should **maintain conversation control**\n",
    "- Example: Research manager combining summaries and fact-checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see another agents-as-tools example: parallel analysis\n",
    "\n",
    "sentiment_analyst = Agent(\n",
    "    name=\"SentimentAnalyst\",\n",
    "    instructions=\"Analyze the sentiment of text. Output: positive, negative, or neutral with brief reasoning.\",\n",
    "    model=\"gpt-4.1\"\n",
    ")\n",
    "\n",
    "keyword_extractor = Agent(\n",
    "    name=\"KeywordExtractor\",\n",
    "    instructions=\"Extract the 3-5 most important keywords from the text.\",\n",
    "    model=\"gpt-4.1\"\n",
    ")\n",
    "\n",
    "content_analyzer = Agent(\n",
    "    name=\"ContentAnalyzer\",\n",
    "    instructions=\"\"\"Analyze content by:\n",
    "    1. Getting sentiment analysis\n",
    "    2. Extracting keywords\n",
    "    3. Providing a combined analysis report\"\"\",\n",
    "    model=\"gpt-4.1\",\n",
    "    tools=[\n",
    "        sentiment_analyst.as_tool(\n",
    "            tool_name=\"analyze_sentiment\",\n",
    "            tool_description=\"Analyze the sentiment of text\"\n",
    "        ),\n",
    "        keyword_extractor.as_tool(\n",
    "            tool_name=\"extract_keywords\",\n",
    "            tool_description=\"Extract key terms from text\"\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating trace Agent workflow with id trace_51d5d852eb0545779d535670f84c04a9\n",
      "Setting current trace: trace_51d5d852eb0545779d535670f84c04a9\n",
      "Creating span <agents.tracing.span_data.AgentSpanData object at 0x11d188ad0> with id None\n",
      "Running agent ContentAnalyzer (turn 1)\n",
      "No conversation_id available for request\n",
      "Creating span <agents.tracing.span_data.ResponseSpanData object at 0x11d1fe8f0> with id None\n",
      "Calling LLM\n",
      "LLM responded\n",
      "Processing output item type=function_call class=ResponseFunctionToolCall\n",
      "Processing output item type=function_call class=ResponseFunctionToolCall\n",
      "Creating span <agents.tracing.span_data.FunctionSpanData object at 0x11d1ecfb0> with id None\n",
      "Creating span <agents.tracing.span_data.FunctionSpanData object at 0x10596bb90> with id None\n",
      "Invoking tool analyze_sentiment\n",
      "Creating span <agents.tracing.span_data.AgentSpanData object at 0x11d1ed490> with id None\n",
      "Running agent SentimentAnalyst (turn 1)\n",
      "Invoking tool extract_keywords\n",
      "Creating span <agents.tracing.span_data.AgentSpanData object at 0x11d1ecb30> with id None\n",
      "Running agent KeywordExtractor (turn 1)\n",
      "No conversation_id available for request\n",
      "Creating span <agents.tracing.span_data.ResponseSpanData object at 0x11d1081e0> with id None\n",
      "Calling LLM\n",
      "No conversation_id available for request\n",
      "Creating span <agents.tracing.span_data.ResponseSpanData object at 0x11d1fcd70> with id None\n",
      "Calling LLM\n",
      "LLM responded\n",
      "Processing output item type=message class=ResponseOutputMessage\n",
      "LLM responded\n",
      "Processing output item type=message class=ResponseOutputMessage\n",
      "Running agent ContentAnalyzer (turn 2)\n",
      "No conversation_id available for request\n",
      "Creating span <agents.tracing.span_data.ResponseSpanData object at 0x11d1d7110> with id None\n",
      "Calling LLM\n",
      "LLM responded\n",
      "Processing output item type=message class=ResponseOutputMessage\n",
      "Resetting current trace\n",
      "Combined Analysis Report:\n",
      "\n",
      "1. Sentiment Analysis:\n",
      "The review expresses a highly positive sentiment. The customer is pleased with both the build quality of the product and the helpfulness of the customer service.\n",
      "\n",
      "2. Extracted Keywords:\n",
      "- Build quality\n",
      "- Customer service\n",
      "- Exceeded expectations\n",
      "\n",
      "3. Summary:\n",
      "The review enthusiastically recommends the product, highlighting its superior build quality and excellent customer service. The overall experience exceeded the customer's expectations.\n"
     ]
    }
   ],
   "source": [
    "review = \"This product exceeded my expectations! The build quality is fantastic and customer service was incredibly helpful when I had questions.\"\n",
    "\n",
    "result = await Runner.run(content_analyzer, f\"Analyze this review:\\n{review}\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Both Patterns\n",
    "\n",
    "You can use handoffs AND agents-as-tools in the same system.\n",
    "\n",
    "Example: A customer service system where:\n",
    "- Triage agent **hands off** to specialists (handoff pattern)\n",
    "- Each specialist **uses tools** for specific subtasks (agents-as-tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import function_tool\n",
    "\n",
    "# Simple tools for the order agent\n",
    "@function_tool\n",
    "def lookup_order(order_id: str) -> str:\n",
    "    \"\"\"Look up order details by ID.\"\"\"\n",
    "    orders = {\n",
    "        \"ORD-001\": \"Laptop, Status: Shipped, ETA: Tomorrow\",\n",
    "        \"ORD-002\": \"Mouse, Status: Delivered\"\n",
    "    }\n",
    "    return orders.get(order_id, f\"Order {order_id} not found\")\n",
    "\n",
    "# Order specialist with tools\n",
    "order_agent = Agent(\n",
    "    name=\"OrderSpecialist\",\n",
    "    instructions=\"You help customers with order inquiries. Use the lookup_order tool to find order details.\",\n",
    "    model=\"gpt-4.1\",\n",
    "    tools=[lookup_order],\n",
    "    handoff_description=\"Hand off for order status, shipping, and delivery questions\"\n",
    ")\n",
    "\n",
    "# General info agent (no special tools needed)\n",
    "general_agent = Agent(\n",
    "    name=\"GeneralInfo\",\n",
    "    instructions=\"You answer general questions about the company, policies, and products.\",\n",
    "    model=\"gpt-4.1\",\n",
    "    handoff_description=\"Hand off for general questions about policies, products, or the company\"\n",
    ")\n",
    "\n",
    "# Triage routes to specialists\n",
    "customer_service = Agent(\n",
    "    name=\"CustomerService\",\n",
    "    instructions=\"Route customers to the right specialist based on their question.\",\n",
    "    model=\"gpt-4.1\",\n",
    "    handoffs=[order_agent, general_agent]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating trace Agent workflow with id trace_c4a4217a3c39454ea34a6c522429e7c9\n",
      "Setting current trace: trace_c4a4217a3c39454ea34a6c522429e7c9\n",
      "Creating span <agents.tracing.span_data.AgentSpanData object at 0x11d188ad0> with id None\n",
      "Running agent CustomerService (turn 1)\n",
      "No conversation_id available for request\n",
      "Creating span <agents.tracing.span_data.ResponseSpanData object at 0x11d1fd4f0> with id None\n",
      "Calling LLM\n",
      "LLM responded\n",
      "Processing output item type=function_call class=ResponseFunctionToolCall\n",
      "Creating span <agents.tracing.span_data.HandoffSpanData object at 0x11b046e40> with id None\n",
      "Creating span <agents.tracing.span_data.AgentSpanData object at 0x11d1edf70> with id None\n",
      "Running agent OrderSpecialist (turn 2)\n",
      "No conversation_id available for request\n",
      "Creating span <agents.tracing.span_data.ResponseSpanData object at 0x11d1097c0> with id None\n",
      "Calling LLM\n",
      "LLM responded\n",
      "Processing output item type=function_call class=ResponseFunctionToolCall\n",
      "Creating span <agents.tracing.span_data.FunctionSpanData object at 0x11d1edc10> with id None\n",
      "Invoking tool lookup_order\n",
      "Tool lookup_order completed.\n",
      "Running agent OrderSpecialist (turn 3)\n",
      "No conversation_id available for request\n",
      "Creating span <agents.tracing.span_data.ResponseSpanData object at 0x11b2bf660> with id None\n",
      "Calling LLM\n",
      "LLM responded\n",
      "Processing output item type=message class=ResponseOutputMessage\n",
      "Resetting current trace\n",
      "Your order (ORD-001) for a laptop has been shipped. The estimated time of arrival is tomorrow. If you need further details or tracking information, let me know!\n"
     ]
    }
   ],
   "source": [
    "# Order question → handoff to order specialist → uses lookup_order tool\n",
    "result = await Runner.run(customer_service, \"Where is my order ORD-001?\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating trace Agent workflow with id trace_1503822d4630462eb8be71f9ca99459a\n",
      "Setting current trace: trace_1503822d4630462eb8be71f9ca99459a\n",
      "Creating span <agents.tracing.span_data.AgentSpanData object at 0x11d189310> with id None\n",
      "Running agent CustomerService (turn 1)\n",
      "No conversation_id available for request\n",
      "Creating span <agents.tracing.span_data.ResponseSpanData object at 0x11d1fd630> with id None\n",
      "Calling LLM\n",
      "LLM responded\n",
      "Processing output item type=function_call class=ResponseFunctionToolCall\n",
      "Creating span <agents.tracing.span_data.HandoffSpanData object at 0x11d1ff480> with id None\n",
      "Creating span <agents.tracing.span_data.AgentSpanData object at 0x11d1edf70> with id None\n",
      "Running agent GeneralInfo (turn 2)\n",
      "No conversation_id available for request\n",
      "Creating span <agents.tracing.span_data.ResponseSpanData object at 0x11d1ff3e0> with id None\n",
      "Calling LLM\n",
      "LLM responded\n",
      "Processing output item type=message class=ResponseOutputMessage\n",
      "Resetting current trace\n",
      "Our return policy may vary depending on the type of product and location. Could you please specify what type of product you are interested in returning or where you made your purchase? This will help me provide you with the most accurate information.\n"
     ]
    }
   ],
   "source": [
    "# General question → handoff to general info agent\n",
    "result = await Runner.run(customer_service, \"What's your return policy?\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Handoffs** transfer control completely - specialist takes over\n",
    "2. **Agents-as-Tools** keep manager in control - manager synthesizes results\n",
    "3. **`handoff_description`** tells the routing agent when to use each handoff\n",
    "4. **`agent.as_tool()`** turns any agent into a callable tool\n",
    "5. **Combine patterns** for complex systems (triage + tools)\n",
    "\n",
    "### Decision Cheat Sheet\n",
    "\n",
    "| Question | If Yes → | If No → |\n",
    "|----------|----------|----------|\n",
    "| Does the specialist complete the whole task? | Handoff | Agents-as-Tools |\n",
    "| Need to combine results from multiple agents? | Agents-as-Tools | Handoff |\n",
    "| Should user interact with specialist directly? | Handoff | Agents-as-Tools |\n",
    "\n",
    "Next up: **Guardrails, Sessions, and Tracing** - making your agents production-ready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BG: Is the RunContextWrapper a tool written in Python? What are the downsides to using that compared to other methods?\n",
    "\n",
    "# OR: is for the tool-call approach any timeout parameter or this happens event driven?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
